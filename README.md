# Intro_to_NLP
Labs and homework from the "Intro to NLP" course in the Technion
## Information on Labs

_Lab0-0_: Setting up the enviroment

_Lab0-1_: Goes over tensor maths and teaches about the torch library


_Lab1-1_: Tokenization, bag/set-of-words, hot-one representation and distances

_Lab1-2_: Text classification

_Lab1-3_: Naive-Bayes classification

_Lab1-4_: Logistic regression, loss function

_Lab1-5_: Learn about huggingFace


_Lab2-1_: N-gram models

_Lab2-2_: RNNs, Bigram models that use RNN

_Lab2-3_: N-gram Feedforward models

_Lab2-4_: Hidden Markov methods

_Lab2-5_: Sequence labeling using RNN


_Lab3-1_: Intro to context-free-grammer (CFG)

_Lab3-2_: Context free parsing using CKY algorithm

_Lab3-3_: PCFG

_Lab3-4_: PCFG parsing and conversion to Chomsky-Normal-Form


_Lab4-1_: First-order-logic, lambda calculus, semantic parsing

_Lab4-2_: SQL semantic parsing

_Lab4-3_: Skipped

_Lab4-4_: Neural Encoder-Decoder methods

_Lab4-5_: Neural Encoder-Decoder methods with attention

##Projects

_Project-1_: In this project we had to classify a dataset of airline information requests using Naive-Bayes, logistic regression, and multilayer perceptron classifiers

_Project-2_: In this one we did sequance labeling using: HMM, RNN, LSTM based approaches

_Project-3_: Parsing the airline questions using the CFG and the PCFC using a CKY algorithm

_Project-4_: Parsed the sequances to turn the questions in SQL queries using syntactic parse trees. Then did it using seq2seq method with and without attention
